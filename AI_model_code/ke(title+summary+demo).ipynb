{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "ENCODER_MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "\n",
    "\n",
    "class SoftLabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        if isinstance(outputs, dict):\n",
    "            logits = outputs[\"logits\"]\n",
    "        else:\n",
    "            logits = outputs.logits\n",
    "\n",
    "        log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
    "        loss = -(labels * log_probs).sum(dim=-1).mean()\n",
    "\n",
    "        if return_outputs:\n",
    "            return loss, outputs\n",
    "        return loss\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    logits = np.array(logits)\n",
    "    labels_soft = np.array(labels)\n",
    "\n",
    "    probs_pred = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "    true_idx = labels_soft.argmax(axis=-1)\n",
    "\n",
    "    pred_idx = probs_pred.argmax(axis=-1)\n",
    "    top1_acc = (pred_idx == true_idx).mean()\n",
    "\n",
    "    k = 3\n",
    "    pred_rank_idx = np.argsort(-probs_pred, axis=-1)\n",
    "    topk_hit = np.any(pred_rank_idx[:, :k] == true_idx[:, None], axis=1)\n",
    "    top3_hit_rate = topk_hit.mean()\n",
    "\n",
    "    eps = 1e-12\n",
    "    ce = -(labels_soft * np.log(probs_pred + eps)).sum(axis=1).mean()\n",
    "\n",
    "    mse = ((probs_pred - labels_soft) ** 2).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return {\n",
    "        \"top1_accuracy\": float(top1_acc),\n",
    "        \"top3_hit_rate\": float(top3_hit_rate),\n",
    "        \"cross_entropy\": float(ce),\n",
    "        \"rmse\": float(rmse),\n",
    "    }\n",
    "\n",
    "\n",
    "def build_demographics_soft_labels(\n",
    "    demo_path1: str,\n",
    "    demo_path2: str,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    df1 = pd.read_excel(demo_path1)\n",
    "    df2 = pd.read_excel(demo_path2)\n",
    "    df_demo = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    df_demo = df_demo[~((df_demo[\"views\"] == 0) & (df_demo[\"ratio\"] == 0))].copy()\n",
    "\n",
    "    df_demo[\"ratio_frac\"] = df_demo[\"ratio\"] / 100.0\n",
    "\n",
    "    df_demo[\"demo_group\"] = df_demo[\"age_group\"].astype(str) + \"_\" + df_demo[\"gender\"].astype(str)\n",
    "\n",
    "    grouped = (\n",
    "        df_demo\n",
    "        .groupby([\"article_id\", \"demo_group\"])\n",
    "        .apply(lambda g: (g[\"views\"] * g[\"ratio_frac\"]).sum() / g[\"views\"].sum())\n",
    "        .reset_index(name=\"soft_label\")\n",
    "    )\n",
    "\n",
    "    label_mat = (\n",
    "        grouped\n",
    "        .pivot(index=\"article_id\", columns=\"demo_group\", values=\"soft_label\")\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    drop_cols = [c for c in label_mat.columns if str(c).startswith(\"전체_\")]\n",
    "    if drop_cols:\n",
    "        print(\"[Demographics] Dropping overall gender groups:\", drop_cols)\n",
    "        label_mat = label_mat.drop(columns=drop_cols)\n",
    "\n",
    "    label_mat = label_mat[label_mat.sum(axis=1) > 0].copy()\n",
    "\n",
    "    row_sum = label_mat.sum(axis=1)\n",
    "    row_sum[row_sum == 0.0] = 1.0\n",
    "    label_mat = label_mat.div(row_sum, axis=0)\n",
    "\n",
    "    demo_labels = list(label_mat.columns)\n",
    "    print(\"[Demographics] demo_labels 개수:\", len(demo_labels))\n",
    "\n",
    "    return label_mat, demo_labels\n",
    "\n",
    "\n",
    "def build_demographics_hard_labels(\n",
    "    demo_path1: str,\n",
    "    demo_path2: str,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    soft_mat, demo_labels = build_demographics_soft_labels(demo_path1, demo_path2)\n",
    "\n",
    "    values = soft_mat.values\n",
    "    major_idx = values.argmax(axis=1)\n",
    "\n",
    "    hard_values = np.zeros_like(values, dtype=np.float32)\n",
    "    hard_values[np.arange(len(major_idx)), major_idx] = 1.0\n",
    "\n",
    "    label_mat_hard = pd.DataFrame(\n",
    "        hard_values,\n",
    "        index=soft_mat.index,\n",
    "        columns=soft_mat.columns,\n",
    "    )\n",
    "\n",
    "    print(\"[Demographics-HARD] demo_labels 개수:\", len(demo_labels))\n",
    "    print(\"[Demographics-HARD] one-hot 예시:\")\n",
    "    print(label_mat_hard.head())\n",
    "\n",
    "    return label_mat_hard, demo_labels\n",
    "\n",
    "\n",
    "def build_referrer_soft_labels(\n",
    "    df_news: pd.DataFrame,\n",
    "    min_ref_count: int = 100,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    df = df_news.copy()\n",
    "\n",
    "    naver_set = {\"네이버\", \"네이버 블로그\"}\n",
    "    if \"period\" in df.columns:\n",
    "        group_is_naver_only = (\n",
    "            df.groupby([\"article_id\", \"period\"])[\"referrer\"]\n",
    "              .transform(lambda s: set(s.unique()).issubset(naver_set))\n",
    "        )\n",
    "        before_rows = len(df)\n",
    "        df = df[~group_is_naver_only].copy()\n",
    "        print(f\"[Referrer] NAVER/NAVER_BLOG only 그룹 제거: {before_rows} -> {len(df)} rows\")\n",
    "    else:\n",
    "        print(\"[Referrer] 'period' 컬럼이 없어 NAVER-only 필터는 article_id 단위로만 적용할 수 있습니다.\")\n",
    "        group_is_naver_only = (\n",
    "            df.groupby([\"article_id\"])[\"referrer\"]\n",
    "              .transform(lambda s: set(s.unique()).issubset(naver_set))\n",
    "        )\n",
    "        before_rows = len(df)\n",
    "        df = df[~group_is_naver_only].copy()\n",
    "        print(f\"[Referrer] NAVER/NAVER_BLOG only (article_id 기준) 제거: {before_rows} -> {len(df)} rows\")\n",
    "\n",
    "    needed_cols = [\"article_id\", \"summary\", \"views_total\", \"referrer\", \"share\"]\n",
    "    for c in needed_cols:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"필수 컬럼 {c} 이(가) 데이터에 없습니다.\")\n",
    "\n",
    "    print(\"[Referrer] 필터 후 referrer 분포:\")\n",
    "    print(df[\"referrer\"].value_counts())\n",
    "\n",
    "    ref_counts = df[\"referrer\"].value_counts()\n",
    "    valid_referrers = ref_counts[ref_counts >= min_ref_count].index.tolist()\n",
    "    print(\"[Referrer] 사용할 referrer 수:\", len(valid_referrers))\n",
    "    print(\"[Referrer] 예시 referrer:\", valid_referrers[:10])\n",
    "\n",
    "    df = df[df[\"referrer\"].isin(valid_referrers)].copy()\n",
    "\n",
    "    df[\"share_frac\"] = df[\"share\"] / 100.0\n",
    "\n",
    "    grouped = (\n",
    "        df\n",
    "        .groupby([\"article_id\", \"referrer\"])\n",
    "        .apply(lambda g: (g[\"views_total\"] * g[\"share_frac\"]).sum() / g[\"views_total\"].sum())\n",
    "        .reset_index(name=\"soft_label\")\n",
    "    )\n",
    "\n",
    "    label_mat = (\n",
    "        grouped\n",
    "        .pivot(index=\"article_id\", columns=\"referrer\", values=\"soft_label\")\n",
    "        .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    row_sum = label_mat.sum(axis=1)\n",
    "    row_sum[row_sum == 0.0] = 1.0\n",
    "    label_mat = label_mat.div(row_sum, axis=0)\n",
    "\n",
    "    ref_labels = list(label_mat.columns)\n",
    "    print(\"[Referrer] 라벨(referrer) 개수:\", len(ref_labels))\n",
    "\n",
    "    label_array = label_mat.values\n",
    "    eps = 1e-12\n",
    "    entropy = -(label_array * np.log(label_array + eps)).sum(axis=1).mean()\n",
    "    print(\"[Referrer] 평균 라벨 엔트로피 H(y):\", entropy)\n",
    "\n",
    "    return label_mat, ref_labels\n",
    "\n",
    "\n",
    "class TextWithDemoVectorDataset(Dataset):\n",
    "    def __init__(self, df, text_col, demo_cols, label_cols, tokenizer, max_length=512):\n",
    "        self.df = df.reset_index(drop=False)\n",
    "        self.text_col = text_col\n",
    "        self.demo_cols = demo_cols\n",
    "        self.label_cols = label_cols\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        text = str(row[self.text_col])\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        input_ids = enc[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = enc[\"attention_mask\"].squeeze(0)\n",
    "\n",
    "        demo_vals = [float(row[c]) for c in self.demo_cols]\n",
    "        demo_feats = torch.tensor(demo_vals, dtype=torch.float32)\n",
    "\n",
    "        label_vals = [float(row[c]) for c in self.label_cols]\n",
    "        labels = torch.tensor(label_vals, dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask,\n",
    "            \"demo_feats\": demo_feats,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "\n",
    "class DemoReferrerModel(torch.nn.Module):\n",
    "    def __init__(self, encoder_name: str, demo_dim: int, num_labels: int):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(encoder_name)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        self.feature_dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(hidden_size + demo_dim, num_labels)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        demo_feats=None,\n",
    "        labels=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if demo_feats is None:\n",
    "            raise ValueError(\"demo_feats (demographics vector)가 필요합니다.\")\n",
    "\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0, :]\n",
    "        pooled = self.dropout(pooled)\n",
    "\n",
    "        x = torch.cat([pooled, demo_feats], dim=-1)\n",
    "        x = self.feature_dropout(x)\n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "\n",
    "def train_referrer_model_with_demo_vector(\n",
    "    news_path: str,\n",
    "    demo_label_mat: pd.DataFrame,\n",
    "    batch_size: int = 16,\n",
    "    lr: float = 1e-5,\n",
    "    num_epochs: int = 5,\n",
    "    max_length: int = 512,\n",
    "    min_ref_count: int = 100,\n",
    "    output_dir: str = \"./koelectra_referrer_with_demo_vector\",\n",
    "):\n",
    "    df_news = pd.read_excel(news_path)\n",
    "\n",
    "    df_news[\"base_text\"] = df_news[\"title\"].fillna(\"\") + \" \" + df_news[\"summary\"].fillna(\"\")\n",
    "\n",
    "    ref_label_mat, ref_labels = build_referrer_soft_labels(\n",
    "        df_news,\n",
    "        min_ref_count=min_ref_count,\n",
    "    )\n",
    "\n",
    "    article_meta = (\n",
    "        df_news\n",
    "        .drop_duplicates(\"article_id\")\n",
    "        .set_index(\"article_id\")[[\"base_text\"]]\n",
    "    )\n",
    "\n",
    "    article_text = article_meta[[\"base_text\"]]\n",
    "\n",
    "    common_ids = ref_label_mat.index.intersection(article_text.index)\n",
    "\n",
    "    article_text = article_text.loc[common_ids]\n",
    "    ref_label_mat = ref_label_mat.loc[common_ids]\n",
    "\n",
    "    demo_for_articles = demo_label_mat.reindex(common_ids)\n",
    "    demo_for_articles = demo_for_articles.fillna(0.0)\n",
    "    valid_mask = demo_for_articles.sum(axis=1) > 0\n",
    "    demo_for_articles = demo_for_articles[valid_mask]\n",
    "\n",
    "    common_ids = demo_for_articles.index.intersection(article_text.index)\n",
    "    article_text = article_text.loc[common_ids]\n",
    "    ref_label_mat = ref_label_mat.loc[common_ids]\n",
    "    demo_for_articles = demo_for_articles.loc[common_ids]\n",
    "\n",
    "    demo_cols = list(demo_for_articles.columns)\n",
    "\n",
    "    dataset_df = article_text.join(demo_for_articles, how=\"inner\")\n",
    "    dataset_df = dataset_df.join(ref_label_mat, how=\"inner\")\n",
    "\n",
    "    print(\"[Step2-Vector] 전체 dataset 크기:\", dataset_df.shape)\n",
    "\n",
    "    dataset_df[ref_labels] = (\n",
    "        dataset_df[ref_labels]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .fillna(0.0)\n",
    "        .astype(\"float32\")\n",
    "    )\n",
    "    dataset_df[demo_cols] = (\n",
    "        dataset_df[demo_cols]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .fillna(0.0)\n",
    "        .astype(\"float32\")\n",
    "    )\n",
    "\n",
    "    dataset_df[\"major_referrer\"] = dataset_df[ref_labels].idxmax(axis=1)\n",
    "    print(\"[Step2-Vector] major_referrer 분포:\")\n",
    "    print(dataset_df[\"major_referrer\"].value_counts(normalize=True))\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        dataset_df,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=dataset_df[\"major_referrer\"],\n",
    "    )\n",
    "\n",
    "    print(\"[Hold-out] train size:\", len(train_df), \" / val size:\", len(val_df))\n",
    "\n",
    "    if len(train_df) == 0 or len(val_df) == 0:\n",
    "        raise ValueError(f\"[ERROR] train/val 데이터가 비었습니다. train={len(train_df)}, val={len(val_df)}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(ENCODER_MODEL_NAME)\n",
    "\n",
    "    train_dataset = TextWithDemoVectorDataset(\n",
    "        train_df,\n",
    "        text_col=\"base_text\",\n",
    "        demo_cols=demo_cols,\n",
    "        label_cols=ref_labels,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    val_dataset = TextWithDemoVectorDataset(\n",
    "        val_df,\n",
    "        text_col=\"base_text\",\n",
    "        demo_cols=demo_cols,\n",
    "        label_cols=ref_labels,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "\n",
    "    model = DemoReferrerModel(\n",
    "        encoder_name=ENCODER_MODEL_NAME,\n",
    "        demo_dim=len(demo_cols),\n",
    "        num_labels=len(ref_labels),\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        learning_rate=lr,\n",
    "        num_train_epochs=num_epochs,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_steps=50,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"top1_accuracy\",\n",
    "        greater_is_better=True,\n",
    "        report_to=\"none\",\n",
    "        save_safetensors=False,\n",
    "        save_total_limit=2,\n",
    "        remove_unused_columns=False,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "\n",
    "    trainer = SoftLabelTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_result = trainer.evaluate()\n",
    "    print(f\"\\n[Step2-Vector @ {output_dir}] 최종 평가 결과 (best top-1 기준):\")\n",
    "    for k, v in eval_result.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    best_ckpt = trainer.state.best_model_checkpoint\n",
    "    print(\"[Step2-Vector] Best checkpoint:\", best_ckpt)\n",
    "    if best_ckpt is not None:\n",
    "        best_model_dir = os.path.join(output_dir, \"best_model\")\n",
    "        print(\"[Step2-Vector] Saving best model to:\", best_model_dir)\n",
    "        os.makedirs(best_model_dir, exist_ok=True)\n",
    "\n",
    "        state_dict = trainer.model.state_dict()\n",
    "        safe_state_dict = {\n",
    "            k: v.detach().cpu().contiguous() for k, v in state_dict.items()\n",
    "        }\n",
    "        torch.save(\n",
    "            safe_state_dict,\n",
    "            os.path.join(best_model_dir, \"pytorch_model.bin\")\n",
    "        )\n",
    "        tokenizer.save_pretrained(best_model_dir)\n",
    "\n",
    "    return model.to(DEVICE), tokenizer, ref_labels, demo_cols, trainer, dataset_df\n",
    "\n",
    "\n",
    "def rank_platforms_with_meta(\n",
    "    title: str,\n",
    "    summary: str,\n",
    "    age_group: str,\n",
    "    gender: str,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    ref_labels: List[str],\n",
    "    demo_cols: List[str],\n",
    "    max_length: int = 512,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        text = (title or \"\") + \" \" + (summary or \"\")\n",
    "        enc = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        target_demo = f\"{age_group}_{gender}\"\n",
    "        demo_vec = [1.0 if col == target_demo else 0.0 for col in demo_cols]\n",
    "        demo_tensor = torch.tensor(demo_vec, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        input_ids = enc[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = enc[\"attention_mask\"].to(DEVICE)\n",
    "        demo_tensor = demo_tensor.to(DEVICE)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            demo_feats=demo_tensor,\n",
    "        )\n",
    "        logits = outputs[\"logits\"]\n",
    "        probs = torch.softmax(logits, dim=-1)[0].cpu().numpy()\n",
    "\n",
    "    ranked = sorted(\n",
    "        zip(ref_labels, probs),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    news_path = \"../Korean_Spoken/news_merged_grouped_final_summary.xlsx\"\n",
    "    demo_path1 = \"../Korean_Spoken/demographics_part001.xlsx\"\n",
    "    demo_path2 = \"../Korean_Spoken/demographics_part002.xlsx\"\n",
    "\n",
    "    demo_soft_mat, demo_labels_soft = build_demographics_soft_labels(demo_path1, demo_path2)\n",
    "    print(\"재구성된 demo_labels_soft 개수:\", len(demo_labels_soft))\n",
    "\n",
    "    (ref_model_soft,\n",
    "     ref_tokenizer_soft,\n",
    "     ref_labels_soft,\n",
    "     demo_cols_soft,\n",
    "     ref_trainer_soft,\n",
    "     ref_dataset_soft) = train_referrer_model_with_demo_vector(\n",
    "         news_path=news_path,\n",
    "         demo_label_mat=demo_soft_mat,\n",
    "         batch_size=8,\n",
    "         lr=1e-5,\n",
    "         num_epochs=5,\n",
    "         max_length=512,\n",
    "         min_ref_count=100,\n",
    "         output_dir=\"./koelectra_referrer_with_demo_vector_soft_demo_nocat\",\n",
    "    )\n",
    "\n",
    "    demo_hard_mat, demo_labels_hard = build_demographics_hard_labels(demo_path1, demo_path2)\n",
    "    print(\"재구성된 demo_labels_hard 개수:\", len(demo_labels_hard))\n",
    "\n",
    "    (ref_model_hard,\n",
    "     ref_tokenizer_hard,\n",
    "     ref_labels_hard,\n",
    "     demo_cols_hard,\n",
    "     ref_trainer_hard,\n",
    "     ref_dataset_hard) = train_referrer_model_with_demo_vector(\n",
    "         news_path=news_path,\n",
    "         demo_label_mat=demo_hard_mat,\n",
    "         batch_size=8,\n",
    "         lr=1e-5,\n",
    "         num_epochs=5,\n",
    "         max_length=512,\n",
    "         min_ref_count=100,\n",
    "         output_dir=\"./koelectra_referrer_with_demo_vector_hard_demo_nocat\",\n",
    "    )\n",
    "\n",
    "    print(\"\\n===================== SOFT vs HARD DEMO 비교 (NO CATEGORY) =====================\")\n",
    "    soft_metrics = ref_trainer_soft.evaluate()\n",
    "    hard_metrics = ref_trainer_hard.evaluate()\n",
    "\n",
    "    metric_names = [\n",
    "        \"eval_loss\",\n",
    "        \"eval_top1_accuracy\",\n",
    "        \"eval_top3_hit_rate\",\n",
    "        \"eval_cross_entropy\",\n",
    "        \"eval_rmse\",\n",
    "    ]\n",
    "\n",
    "    print(\"\\n[Metrics 비교]\")\n",
    "    print(\"{:<22} | {:>12} | {:>12}\".format(\"metric\", \"soft_demo\", \"hard_demo\"))\n",
    "    print(\"-\" * 52)\n",
    "    for m in metric_names:\n",
    "        sv = soft_metrics.get(m, None)\n",
    "        hv = hard_metrics.get(m, None)\n",
    "        print(\"{:<22} | {:>12.6f} | {:>12.6f}\".format(\n",
    "            m,\n",
    "            sv if sv is not None else float(\"nan\"),\n",
    "            hv if hv is not None else float(\"nan\"),\n",
    "        ))\n",
    "\n",
    "    example_title = \"10대 여성 소비 트렌드: 편의점과 패션의 변화\"\n",
    "    example_summary = \"10대 여성의 소비 패턴을 분석하고 주요 플랫폼별 반응을 정리했다.\"\n",
    "    example_age = \"10대\"\n",
    "    example_gender = \"여\"\n",
    "\n",
    "    print(\"\\n[예측] 플랫폼 추천 순위 (상위 5개) - SOFT DEMO 모델:\")\n",
    "    ranked_soft = rank_platforms_with_meta(\n",
    "        title=example_title,\n",
    "        summary=example_summary,\n",
    "        age_group=example_age,\n",
    "        gender=example_gender,\n",
    "        model=ref_model_soft,\n",
    "        tokenizer=ref_tokenizer_soft,\n",
    "        ref_labels=ref_labels_soft,\n",
    "        demo_cols=demo_cols_soft,\n",
    "        max_length=512,\n",
    "    )\n",
    "    for ref, p in ranked_soft[:5]:\n",
    "        print(f\"[SOFT] {ref}: {p:.4f}\")\n",
    "\n",
    "    print(\"\\n[예측] 플랫폼 추천 순위 (상위 5개) - HARD DEMO 모델:\")\n",
    "    ranked_hard = rank_platforms_with_meta(\n",
    "        title=example_title,\n",
    "        summary=example_summary,\n",
    "        age_group=example_age,\n",
    "        gender=example_gender,\n",
    "        model=ref_model_hard,\n",
    "        tokenizer=ref_tokenizer_hard,\n",
    "        ref_labels=ref_labels_hard,\n",
    "        demo_cols=demo_cols_hard,\n",
    "        max_length=512,\n",
    "    )\n",
    "    for ref, p in ranked_hard[:5]:\n",
    "        print(f\"[HARD] {ref}: {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ebd3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
